{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to chromedriver and set the browser to chrome\n",
    "executable_path = {'executable_path': 'C:\\Program Files (x86)\\Chromedriver\\chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare a URL variable to visit the nasa news page and visit that URL.  Pause for 2 seconds to allow the page to fully load.\n",
    "url = 'https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest'\n",
    "browser.visit(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape the data into BeautifulSoup\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#Find the title and text for the most recent article\n",
    "title = soup.find(class_='content_title')\n",
    "text = soup.find(class_='rollover_description_inner')\n",
    "news_title = title.text\n",
    "news_text = text.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the following URL, scrape the data into BS to be discected.  \n",
    "url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "browser.visit(url)\n",
    "\n",
    "# Declare a partial URL to be used later\n",
    "beginning_url = 'https://www.jpl.nasa.gov'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design an XPATH selector to grab the featured image from the page\n",
    "xpath = '//a[@class=\"button fancybox\"]'\n",
    "results = browser.find_by_xpath(xpath)\n",
    "img = results[0]\n",
    "img.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/spaceimages/images/mediumsize/PIA14712_ip.jpg'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape the browser into soup and use soup to find the full resolution image of mars\n",
    "# Save the image url to a variable called `img_url`\n",
    "time.sleep(2)\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "img_url = soup.find(\"img\", class_=\"fancybox-image\")[\"src\"]\n",
    "img_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA14712_ip.jpg\n"
     ]
    }
   ],
   "source": [
    "# Use the partial URL from earlier to combine it with the other partial URL.  \n",
    "featured_image_url = beginning_url + img_url\n",
    "featured_image_url\n",
    "print(featured_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare our new URL as twitter, visit the page, and scrape the data into BS.\n",
    "url = 'https://twitter.com/marswxreport?lang=en'\n",
    "browser.visit(url)\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sol 2085 (2018-06-18), Sunny, high -24C/-11F, low -57C/-70F, pressure at 7.72 hPa, daylight 05:18-17:22'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the most recent tweet and store it in a variable\n",
    "tweets = soup.find_all(\"p\", class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\")\n",
    "for tweet in tweets:\n",
    "    sol = tweet.text[0:3]\n",
    "    if sol ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sol 2085 (2018-06-18), Sunny, high -24C/-11F, low -57C/-70F, pressure at 7.72 hPa, daylight 05:18-17:22'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atweet = soup.find_all(\"p\", class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\")\n",
    "for tweet in atweet:\n",
    "    sol = tweet.text[0:3]\n",
    "    if sol == \"Sol\":\n",
    "        weather = tweet.text\n",
    "        break\n",
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare another new URL for mars facts and read the tables on the page using pandas.\n",
    "url = 'https://space-facts.com/mars/'\n",
    "tables = pd.read_html(url)\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the data in a dataframe for later\n",
    "facts_df = tables[0]\n",
    "facts_df.columns = [\"Description\", \"Value\"]\n",
    "facts_df.set_index('Description', inplace=True)\n",
    "facts_df.to_html('table.html')\n",
    "facts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_table = facts_df.to_html()\n",
    "html_table = html_table.replace('\\n', '')\n",
    "html_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare another URL to get enhanced images of the 4 hemispheres of mars.  Scrape the data into BS to get links to the enhanced images.\n",
    "url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "browser.visit(url)\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "base_url = \"https://astrogeology.usgs.gov\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the individual URL for each hemisphere and store them in the img_url list to be iterated through.\n",
    "hemispheres = soup.find_all(\"div\", class_=\"item\")\n",
    "img_url = []\n",
    "for h in hemispheres:\n",
    "    img_url.append(h.a[\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the img_url list, go to each link, scrape the data into soup, and locate the title and hyperlink for each \n",
    "# enhanced image.  Then store the information as a dictionary.\n",
    "\n",
    "hemisphere_image_urls = []\n",
    "\n",
    "for hemi in img_url:\n",
    "    url = base_url + hemi\n",
    "    browser.visit(url)\n",
    "    time.sleep(2)\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    links = soup.find_all(class_=\"downloads\")\n",
    "    link = links[0].ul\n",
    "    interum_links = []\n",
    "    header = soup.find(class_=\"title\")\n",
    "    hemi_title = header.text\n",
    "    print(hemi_title)\n",
    "    for x in link:\n",
    "        interum_links.append(x)\n",
    "    full_link = interum_links[1].a[\"href\"]\n",
    "    print(full_link)\n",
    "    print(\"-\"*40)\n",
    "    hemisphere_image_urls.append({\"title\": hemi_title, \"img_url\": full_link})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dictionary = {\"news_title\": news_title,\n",
    "                      \"news_text\": news_text,\n",
    "                      \"featured_image_url\": featured_image_url,\n",
    "                      \"mars_weather\": mars_weather,\n",
    "                      \"hemisphere_image_urls\": hemisphere_image_urls,\n",
    "                      \"facts_df\": facts_df}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
